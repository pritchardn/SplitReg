"""
This script generates runfiles for supercomputer use.
"""

import os

models = {
    "FC": [
        ("FC_LATENCY", "LATENCY"),
    ]
}
datasets = ["HERA"]
delta_normalization = [True, False]

scratch_path = "/scratch/pawsey0411/npritchard"
software_path = "/software/projects/pawsey0411/npritchard/setonix/2023.08/python"
hpc_account = "pawsey0411"


def prepare_singlerun(
        model,
        encoding,
        dataset,
        forward_step_exposure="None",
        delta_norm=False,
        num_nodes=1,
        patch_size=32,
):
    forward_step_directory = (
        '''/${FORWARD_EXPOSURE}"''' if forward_step_exposure != "None" else '"'
    )
    limit = 1.0 if dataset.find("HERA") >= 0 else 0.15
    runfiletext = (
            f"""#!/bin/bash
#SBATCH --job-name=SNN-SUPER-{model}-{encoding}-{dataset}
#SBATCH --nodes={num_nodes}
#SBATCH --time=24:00:00
#SBATCH --exclusive
#SBATCH --output=super_%A_%a.out
#SBATCH --error=super_%A_%a.err
#SBATCH --array=0-9
#SBATCH --partition=gpu
#SBATCH --account={hpc_account}-gpu

export DATASET="{dataset}"
export LIMIT="{limit}"
export MODEL_TYPE="{model}"
export ENCODER_METHOD="{encoding}"
export FORWARD_EXPOSURE="{forward_step_exposure}"
export NNODES="{num_nodes}"
export DELTA_NORMALIZATION="{delta_norm}"
export PATCH_SIZE={patch_size}

module load python/3.10.10

cd {software_path}/SNN-SPLITREG/src
source {software_path}/snn-nln/bin/activate

export DATA_PATH="{scratch_path}/data"
export OUTPUT_DIR="{scratch_path}/outputs/snn-splitreg/${{MODEL_TYPE}}/${{ENCODER_METHOD}}/${{DATASET}}/${{DELTA_NORMALIZATION}}/${{PATCH_SIZE}}/${{LIMIT}}"""
            + forward_step_directory
            + """
export FI_CXI_DEFAULT_VNI=$(od -vAn -N4 -tu < /dev/urandom)
export MPICH_OFI_STARTUP_CONNECT=1
export MPICH_OFI_VERBOSE=1
export MPICH_GPU_SUPPORT_ENABLED=1
export OMP_PLACES=cores     
export OMP_PROC_BIND=close  
   
srun -N 1 -n 1 -c 64 --gpus-per-task=8 --gpu-bind=closest python3 main.py
    """
    )
    return runfiletext


def prepare_optuna(
        model,
        encoding,
        dataset,
        limit,
        forward_step_exposure="None",
        delta_norm=False,
        num_nodes=1,
):
    forward_step_directory = (
        '''/${FORWARD_EXPOSURE}"''' if forward_step_exposure != "None" else '"'
    )
    study_name = (
            f"""export STUDY_NAME="SNN-SPLITREG-B-${{DATASET}}-${{ENCODER_METHOD}}-${{MODEL_TYPE}}-{limit}"""
            + ("""-${FORWARD_EXPOSURE}""" if forward_step_exposure != "None" else """""")
            + '-${DELTA_NORMALIZATION}"'
    )
    runfiletext = (
            f"""#!/bin/bash
#SBATCH --job-name=SNN-SUPER-{model}-{encoding}-{dataset}
#SBATCH --nodes=1
#SBATCH --time=24:00:00
#SBATCH --exclusive
#SBATCH --output=super_%A_%a.out
#SBATCH --error=super_%A_%a.err
#SBATCH --array=0-49%4
#SBATCH --partition=gpu
#SBATCH --account={hpc_account}-gpu

export DATASET="{dataset}"
export LIMIT="{limit / 100}"
export MODEL_TYPE="{model}"
export ENCODER_METHOD="{encoding}"
export FORWARD_EXPOSURE="{forward_step_exposure}"
export NNODES=1
export DELTA_NORMALIZATION="{delta_norm}"
export PLOT="false"
export EPOCHS=25


module load python/3.10.10

cd {software_path}/SNN-SPLITREG/src
source {software_path}/snn-nln/bin/activate

export DATA_PATH="{scratch_path}/data"
export OPTUNA_DB=${{OPTUNA_URL}} # Need to change on super-computer before submitting\n"""
            + study_name
            + f"""
export OUTPUT_DIR="{scratch_path}/outputs/snn-splitreg/optuna/${{MODEL_TYPE}}/${{ENCODER_METHOD}}/${{DATASET}}/${{DELTA_NORMALIZATION}}/${{NUM_HIDDEN}}/${{LIMIT}}"""
            + forward_step_directory
            + """
export FI_CXI_DEFAULT_VNI=$(od -vAn -N4 -tu < /dev/urandom)
export MPICH_OFI_STARTUP_CONNECT=1
export MPICH_OFI_VERBOSE=1
export MPICH_GPU_SUPPORT_ENABLED=1
export OMP_PLACES=cores     
export OMP_PROC_BIND=close  

srun -N 1 -n 1 -c 64 --gpus-per-task=8 --gpu-bind=closest python3 optuna_main.py
"""
    )
    return runfiletext


def write_bashfile(out_dir, name, runfiletext):
    with open(os.path.join(out_dir, f"{name}.sh"), "w") as f:
        f.write(runfiletext)


def write_runfiles(out_dir, model, encoding, dataset, num_nodes, delta_norm, patch_size):
    write_bashfile(
        out_dir,
        f"{dataset}-{encoding}-{patch_size}",
        prepare_singlerun(
            model,
            encoding,
            dataset,
            delta_norm=delta_norm,
            num_nodes=num_nodes,
            patch_size=patch_size,
        ),
    )
    limit = 10
    write_bashfile(
        out_dir,
        f"optuna-{dataset}-{encoding}-{limit}-{patch_size}",
        prepare_optuna(
            model,
            encoding,
            dataset,
            limit,
            delta_norm=delta_norm,
            num_nodes=num_nodes,
        ),
    )
    limit = 100
    write_bashfile(
        out_dir,
        f"optuna-{dataset}-{encoding}-{limit}-{patch_size}",
        prepare_optuna(
            model,
            encoding,
            dataset,
            limit,
            delta_norm=delta_norm,
            num_nodes=num_nodes,
        ),
    )


def main(out_dir, num_nodes):
    for major_model, minor_models in models.items():
        for model, encoding in minor_models:
            for dataset in datasets:
                for delta_norm in delta_normalization:
                    out_dir_temp = os.path.join(
                        out_dir,
                        major_model,
                        encoding,
                        dataset,
                        "DELTA_NORM" if delta_norm else "ORIGINAL",
                    )
                    os.makedirs(out_dir_temp, exist_ok=True)
                    for patch_size in [8, 32, 64, 128, 256, 512]:
                        write_runfiles(
                            out_dir_temp,
                            model,
                            encoding,
                            dataset,
                            num_nodes,
                            delta_norm,
                            patch_size
                        )


if __name__ == "__main__":
    main(f".{os.sep}src{os.sep}hpc{os.sep}pawsey", 1)
